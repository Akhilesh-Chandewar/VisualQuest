{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIHjFKR4DzfvQSXvLd/Q9W"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEIMnNorrBay"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from skimage import io, img_as_ubyte\n",
        "from skimage.transform import resize\n",
        "import h5py\n",
        "from skimage.filters import roberts, sobel\n",
        "from skimage.color import rgb2lab, rgb2gray\n",
        "import cv2\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_custom_features(img):\n",
        "    # Color features\n",
        "    LAB_img = rgb2lab(img)\n",
        "    A_img = LAB_img[:,:,1]\n",
        "    A_feat = A_img.mean()\n",
        "\n",
        "    B_img = LAB_img[:,:,2]\n",
        "    B_feat = B_img.mean()\n",
        "\n",
        "    # Textural features based on the gray image\n",
        "    gray_img = rgb2gray(img)\n",
        "    gray_img = resize(gray_img, (256,256)) # Resize to smaller size\n",
        "    gray_img = img_as_ubyte(gray_img)\n",
        "\n",
        "    # Entropy\n",
        "    entropy_img = entropy(gray_img, disk(3))\n",
        "    entropy_mean = entropy_img.mean()\n",
        "    entropy_std = entropy_img.std()\n",
        "\n",
        "    roberts_img = roberts(gray_img)\n",
        "    roberts_mean = roberts_img.mean()\n",
        "\n",
        "    sobel_img = sobel(gray_img)\n",
        "    sobel_mean = sobel_img.mean()\n",
        "\n",
        "    # Gabor filters\n",
        "    kernel1 = cv2.getGaborKernel((9, 9), 3, np.pi/4, np.pi, 0.5, 0, ktype=cv2.CV_32F)\n",
        "    gabor1 = (cv2.filter2D(gray_img, cv2.CV_8UC3, kernel1)).mean()\n",
        "\n",
        "    kernel2 = cv2.getGaborKernel((9, 9), 3, np.pi/2, np.pi/4, 0.9, 0, ktype=cv2.CV_32F)\n",
        "    gabor2 = (cv2.filter2D(gray_img, cv2.CV_8UC3, kernel2)).mean()\n",
        "\n",
        "    kernel3 = cv2.getGaborKernel((9, 9), 5, np.pi/2, np.pi/2, 0.1, 0, ktype=cv2.CV_32F)\n",
        "    gabor3 = (cv2.filter2D(gray_img, cv2.CV_8UC3, kernel3)).mean()\n",
        "\n",
        "    custom_features = np.array([A_feat, B_feat, entropy_mean, entropy_std, roberts_mean,\n",
        "                                sobel_mean, gabor1, gabor2, gabor3])\n",
        "\n",
        "    return custom_features"
      ],
      "metadata": {
        "id": "jzHXJ-7ZsKay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_file(filename):\n",
        "    valid_extensions = (\n",
        "        '.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.gif', '.webp',\n",
        "        '.heif', '.heic', '.ppm', '.pgm', '.pbm', '.pnm', '.svg', '.ico'\n",
        "    )\n",
        "    return filename.lower().endswith(valid_extensions)\n"
      ],
      "metadata": {
        "id": "eKxHvfd_yzoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"all_images/\"\n",
        "feats = []\n",
        "names = []\n",
        "\n",
        "for im in os.listdir(path):  # iterate through all images to extract features\n",
        "    if is_image_file(im):  # Check if it's an image file\n",
        "        print(\"Extracting features from image - \", im)\n",
        "        img = io.imread(os.path.join(path, im))  # Read the image\n",
        "\n",
        "        # Extract features\n",
        "        X = extract_custom_features(img)\n",
        "        feats.append(X)\n",
        "        names.append(im)\n",
        "    else:\n",
        "        print(f\"Skipping non-image file: {im}\")\n",
        "\n",
        "# Convert the list of features to a numpy array after the loop\n",
        "feats = np.array(feats)\n",
        "\n",
        "# Save the extracted features and names of images into an h5 file\n",
        "feature_file = \"CustomFeatures.h5\"\n",
        "print(\"Saving features to h5 file\")\n",
        "\n",
        "h5f = h5py.File(feature_file, 'w')\n",
        "h5f.create_dataset('dataset_1', data=feats)\n",
        "h5f.create_dataset('dataset_2', data=np.string_(names))\n",
        "h5f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxJ-wZyww1Yw",
        "outputId": "8d8c418f-3981-49cd-93a3-7d18fd19386c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from image -  horse2.jpg\n",
            "Extracting features from image -  monkey2.jpg\n",
            "Extracting features from image -  horse1.jpg\n",
            "Extracting features from image -  2.png\n",
            "Extracting features from image -  1.png\n",
            "Extracting features from image -  zebra1.jpg\n",
            "Extracting features from image -  zebra2.jpg\n",
            "Extracting features from image -  4.png\n",
            "Extracting features from image -  tiger1.jpg\n",
            "Extracting features from image -  tiger2.jpg\n",
            "Extracting features from image -  monkey1.jpg\n",
            "Extracting features from image -  chihuahua.JPG\n",
            "Skipping non-image file: .ipynb_checkpoints\n",
            "Extracting features from image -  irish_terrier.JPG\n",
            "Saving features to h5 file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h5f = h5py.File(\"CustomFeatures.h5\",'r')\n",
        "feats = h5f['dataset_1'][:]\n",
        "imgNames = h5f['dataset_2'][:]\n",
        "h5f.close()"
      ],
      "metadata": {
        "id": "jxRYq-NIy8AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queryImg = io.imread(\"query_images/tiger3.jpg\")"
      ],
      "metadata": {
        "id": "_UmefhdP2s1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = extract_custom_features(queryImg)"
      ],
      "metadata": {
        "id": "iOAny7AS2vT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "from scipy import spatial\n",
        "for i in range(feats.shape[0]):\n",
        "    score = 1-spatial.distance.cosine(X, feats[i])\n",
        "    scores.append(score)\n",
        "scores = np.array(scores)\n",
        "rank_ID = np.argsort(scores)[::-1]\n",
        "rank_score = scores[rank_ID]"
      ],
      "metadata": {
        "id": "CLaCsTZN2_OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_num_matches = 3\n",
        "imlist = [imgNames[index] for i,index in enumerate(rank_ID[0:max_num_matches])]\n",
        "print(\"top %d images in order are: \" %max_num_matches, imlist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cudmamkh3JnP",
        "outputId": "14a1753e-3df7-47c0-a73b-a99722f95862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top 3 images in order are:  [b'tiger1.jpg', b'monkey1.jpg', b'tiger2.jpg']\n"
          ]
        }
      ]
    }
  ]
}